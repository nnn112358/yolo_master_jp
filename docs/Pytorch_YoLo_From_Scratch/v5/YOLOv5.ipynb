{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e2b6e56",
   "metadata": {},
   "source": "### 使用データセットアドレス：\nhttps://www.kaggle.com/datasets/ultralytics/coco128",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "0acc9a42",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nfrom torch.utils.data import Dataset, random_split, DataLoader\nimport os\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport numpy as np\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom matplotlib.font_manager import FontProperties\n\n# YOLOデータセットクラス\nclass YOLODataset(Dataset):\n    def __init__(self, image_dir, label_dir, img_size=(640, 640), classes=80):\n        self.image_dir = image_dir\n        self.label_dir = label_dir\n        self.img_size = img_size\n        self.classes = classes\n\n        # 画像とラベルファイルのパスを取得してソート\n        self.image_files = sorted([os.path.join(image_dir, file) for file in os.listdir(image_dir)])\n        self.label_files = sorted([os.path.join(label_dir, file) for file in os.listdir(label_dir)])\n\n        # 画像の変換操作を定義\n        self.transform = transforms.Compose([\n            transforms.Resize(img_size),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        ])\n\n    def __len__(self):\n        return len(self.image_files)\n\n    def __getitem__(self, idx):\n        image_path = self.image_files[idx]\n        label_path = self.label_files[idx]\n\n        # 画像を読み込んで変換\n        image = Image.open(image_path).convert('RGB')\n        image = self.transform(image)\n\n        # ラベルを読み込み\n        labels = []\n        with open(label_path, 'r') as f:\n            lines = f.readlines()\n            for line in lines:\n                parts = line.strip().split()\n                class_id = int(parts[0])\n                x_center, y_center, width, height = map(float, parts[1:])\n                labels.append([class_id, x_center, y_center, width, height])\n        labels = torch.tensor(labels)\n\n        return image, labels\n\n\n# カスタムcollate関数、異なる長さのラベルを処理するため\ndef custom_collate_fn(batch):\n    images = []\n    labels = []\n    for image, label in batch:\n        images.append(image)\n        labels.append(label)\n\n    # 画像テンソルにtorch.stackを使用\n    images = torch.stack(images, dim=0)\n    # ラベルテンソルはリストで格納\n    labels = labels  \n\n    return images, labels\n\n\n# データセットパスとクラスリスト\ntrain_image_dir = '../datasets/coco8/images/train'  #具体的な需要に応じてファイルアドレスを修正\ntrain_label_dir = '../datasets/coco8/labels/train'\nval_image_dir = '../datasets/coco8/images/val'\nval_label_dir = '../datasets/coco8/labels/val'\n\nclasses = {\n    0: 'person 人', 1: 'bicycle 自転車', 2: 'car 車', 3: 'motorcycle オートバイ', \n    4: 'airplane 飛行機', 5: 'bus バス', 6: 'train 電車', 7: 'truck トラック', \n    8: 'boat ボート', 9: 'traffic light 信号機', 10: 'fire hydrant 消火栓', \n    11: 'stop sign 停止標識', 12: 'parking meter パーキングメーター', 13: 'bench ベンチ',\n    14: 'bird 鳥', 15: 'cat 猫', 16: 'dog 犬', 17: 'horse 馬', \n    18: 'sheep 羊', 19: 'cow 牛', 20: 'elephant 象', 21: 'bear 熊', \n    22: 'zebra シマウマ', 23: 'giraffe キリン', 24: 'backpack バックパック', \n    25: 'umbrella 傘', 26: 'handbag ハンドバッグ', 27: 'tie ネクタイ', \n    28: 'suitcase スーツケース', 29: 'frisbee フリスビー', 30: 'skis スキー板', \n    31: 'snowboard スノーボード', 32: 'sports ball スポーツボール', 33: 'kite 凧', \n    34: 'baseball bat 野球バット', 35: 'baseball glove 野球グローブ', \n    36: 'skateboard スケートボード', 37: 'surfboard サーフボード', \n    38: 'tennis racket テニスラケット', 39: 'bottle ボトル', \n    40: 'wine glass ワイングラス', 41: 'cup カップ', 42: 'fork フォーク', \n    43: 'knife ナイフ', 44: 'spoon スプーン', 45: 'bowl ボウル', 46: 'banana バナナ', \n    47: 'apple りんご', 48: 'sandwich サンドイッチ', 49: 'orange オレンジ', \n    50: 'broccoli ブロッコリー', 51: 'carrot ニンジン', 52: 'hot dog ホットドッグ', \n    53: 'pizza ピザ', 54: 'donut ドーナツ', 55: 'cake ケーキ', \n    56: 'chair 椅子', 57: 'couch ソファ', 58: 'potted plant 鉢植え', \n    59: 'bed ベッド', 60: 'dining table ダイニングテーブル', 61: 'toilet トイレ', \n    62: 'tv テレビ', 63: 'laptop ノートパソコン', 64: 'mouse マウス', \n    65: 'remote リモコン', 66: 'keyboard キーボード', 67: 'cell phone 携帯電話', \n    68: 'microwave 電子レンジ', 69: 'oven オーブン', 70: 'toaster トースター', \n    71: 'sink シンク', 72: 'refrigerator 冷蔵庫', 73: 'book 本', \n    74: 'clock 時計', 75: 'vase 花瓶', 76: 'scissors はさみ', \n    77: 'teddy bear テディベア', 78: 'hair drier ヘアドライヤー', \n    79: 'toothbrush 歯ブラシ'\n}\n\n# データセットを作成\ntrain_dataset = YOLODataset(train_image_dir, train_label_dir, img_size=(640, 640), classes=classes)\ntest_dataset = YOLODataset(val_image_dir, val_label_dir, img_size=(640, 640), classes=classes)\n\n# データローダーを作成\ntrain_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate_fn)\ntest_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=custom_collate_fn)\n\n# データ読み込みテスト\nfor batch_i, (imgs, targets) in enumerate(train_dataloader):\n    print(f\"\\nBatch {batch_i}:\")\n    print(f\"Images shape: {imgs.shape}\")\n    print(f\"Number of targets: {len(targets)}\")\n    for i, target in enumerate(targets):\n        print(f\"  Target {i} shape: {target.shape}\")\n    print(\"\\nDetailed information:\")\n    for i, (target, img_name) in enumerate(zip(targets, train_dataset.image_files)):\n        print(f\"\\nImage {i}:\")\n        print(f\"  File name: {os.path.basename(img_name)}\")\n        print(f\"  Target shape: {target.shape}\")\n        if len(target) > 0:\n            print(f\"  Number of objects: {target.shape[0]}\")\n            print(f\"  First object (class, x, y, w, h): {target[0].tolist()}\")"
  },
  {
   "cell_type": "code",
   "id": "6a5cbc5a",
   "metadata": {},
   "outputs": [],
   "source": "from matplotlib.font_manager import FontProperties\n# 日本語フォントの設定\nfont_path = '../resource/SimHei.ttf'  # システムのフォントパスに応じて調整してください。repoファイル内にあるのでそのアドレスに変更できます\nfont_prop = FontProperties(fname=font_path)\n\ndef plot_image_with_boxes(image, labels, img_name=None, class_names=None, figsize=(10, 10)):\n    \"\"\"\n    画像とバウンディングボックスを可視化\n\n    Args:\n        image: torch.Tensor (C, H, W) - 正規化後の画像\n        labels: torch.Tensor (num_objects, 5) - [class, x_center, y_center, width, height]\n        img_name: str - 画像ファイル名\n        class_names: dict - クラスIDから名前へのマッピング\n        figsize: tuple - 画像表示サイズ\n    \"\"\"\n    # 画像フォーマットを変換\n    img = image.permute(1, 2, 0).numpy()\n\n    # 逆正規化\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    img = std * img + mean\n    img = np.clip(img, 0, 1)\n\n    # 図形を作成\n    fig, ax = plt.subplots(1, figsize=figsize)\n    ax.imshow(img)\n\n    # 画像サイズを取得\n    height, width = img.shape[:2]\n\n    # 異なるクラスの色を設定\n    colors = plt.cm.hsv(np.linspace(0, 1, 81))[:, :3]\n\n    # 各バウンディングボックスを描画\n    for label in labels:\n        class_id = int(label[0])\n        x_center = float(label[1]) * width\n        y_center = float(label[2]) * height\n        w = float(label[3]) * width\n        h = float(label[4]) * height\n\n        # 左上角座標を計算\n        x = x_center - w / 2\n        y = y_center - h / 2\n\n        # ラベル位置が画像範囲内にあるかチェック\n        if x >= 0 and y >= 0 and x + w <= width and y + h <= height:\n            # このクラスの色を取得\n            color = colors[class_id % len(colors)]\n\n            # 矩形を作成\n            rect = patches.Rectangle(\n                (x, y), w, h,\n                linewidth=2,\n                edgecolor=color,\n                facecolor='none'\n            )\n            ax.add_patch(rect)\n\n            class_name = class_names[class_id]\n\n            # ラベル背景ボックスを描画\n            plt.text(\n                x, y - 10,  # ラベル位置を調整、物体を遮らないように\n                class_name,\n                bbox=dict(facecolor=color, alpha=0.8),\n                color='white',\n                fontsize=12,\n                fontproperties=font_prop\n            )\n\n    # 画像タイトルを追加\n    if img_name:\n        plt.title(img_name, fontproperties=font_prop)\n\n    plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\n# 可視化をテスト\nfor batch_i, (imgs, targets) in enumerate(train_dataloader):\n    for i, (img, target) in enumerate(zip(imgs, targets)):\n        plot_image_with_boxes(img, target, img_name=f\"Image_{batch_i}_{i}.jpg\", class_names=classes, figsize=(8, 8))\n    break  # 1つのバッチのみ可視化"
  },
  {
   "cell_type": "markdown",
   "id": "a7ce4da3",
   "metadata": {},
   "source": [
    "![](./image/YOLOv5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999f2f4",
   "metadata": {},
   "source": [
    "<img src=\"./image/ConBNSiLU.png\" alt=\"ConBNSiLU模块\" width=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "id": "5440f24a",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F \n\nclass ConvBNSiLU(nn.Module):\n    # 図中c=output_size,k=kernel_size,s=stride,p=padding,後続コードでも同様\n    def __init__(self, input_size, output_size, kernel_size, stride, padding):\n        super(ConvBNSiLU, self).__init__()\n        self.conv = nn.Conv2d(input_size,output_size, kernel_size, stride, padding=padding if padding is not None else kernel_size//2)\n        self.bn = nn.BatchNorm2d(output_size)\n        self.act = nn.SiLU()\n\n    def forward(self, x):\n        return self.act(self.bn(self.conv(x)))\ninput_size = 3\noutput_size = 64\nkernel_size = 6\nstride = 2\npadding = 2\n# 入力テンソル、入力サイズを [batch_size, channels, height, width] と仮定\ninput_tensor = torch.randn(1, input_size, 640, 640)\n\nconvbnsilu = ConvBNSiLU(input_size, output_size, kernel_size, stride, padding)\noutput = convbnsilu(input_tensor)\nprint(output.shape)    \n\n#出力次元は図中のP1出力と一致"
  },
  {
   "cell_type": "markdown",
   "id": "bab9db06",
   "metadata": {},
   "source": [
    "<img src=\"./image/bottleneck1.png\" alt=\"图片描述\" width=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "id": "7d0d2371",
   "metadata": {},
   "outputs": [],
   "source": "# BottleNeck1モジュール\nclass BottleNeck1(nn.Module):\n    def __init__(self,input_size,output_size,kernel_size,stride,padding):\n        super(BottleNeck1,self).__init__()\n        self.conv1=ConvBNSiLU(input_size,output_size=input_size,kernel_size=1,stride=1,padding=0)\n        self.conv2=ConvBNSiLU(input_size,output_size=input_size,kernel_size=3,stride=1,padding=1)\n    def forward(self,x):\n        x1=self.conv1(x)\n        x1=self.conv2(x1)\n        return torch.cat((x,x1),dim=1)\n\ninput_size = 3\n\n# 入力テンソル、入力サイズを [batch_size, channels, height, width] と仮定\ninput_tensor = torch.randn(1, input_size, 640, 640)\n\nbottleneck1 = BottleNeck1(input_size, input_size, kernel_size, stride, padding)\noutput = bottleneck1(input_tensor)\nprint(output.shape)    \n\n#出力次元は図中の出力と一致    "
  },
  {
   "cell_type": "markdown",
   "id": "e6500077",
   "metadata": {},
   "source": [
    "<img src=\"./image/bottleneck2.png\" alt=\"图片描述\" width=\"300\" />"
   ]
  },
  {
   "cell_type": "code",
   "id": "b18e70ba",
   "metadata": {},
   "outputs": [],
   "source": "# BottleNeck2モジュール\nclass BottleNeck2(nn.Module):\n    def __init__(self,input_size,output_size,kernel_size,stride,padding):\n        super(BottleNeck2,self).__init__()\n        self.conv1=ConvBNSiLU(input_size,output_size=input_size,kernel_size=1,stride=1,padding=0)\n        self.conv2=ConvBNSiLU(input_size,output_size=input_size,kernel_size=3,stride=1,padding=1)\n    def forward(self,x):\n        x1=self.conv1(x)\n        x1=self.conv2(x1)\n        return x1\n\ninput_size = 3\n\n# 入力テンソル、入力サイズを [batch_size, channels, height, width] と仮定\ninput_tensor = torch.randn(1, input_size, 640, 640)\n\nbottleneck2 = BottleNeck2(input_size, input_size, kernel_size, stride, padding)\noutput = bottleneck2(input_tensor)\nprint(output.shape)    \n\n#出力次元は図中の出力と一致    "
  },
  {
   "cell_type": "markdown",
   "id": "8a465b2b",
   "metadata": {},
   "source": [
    "<img src=\"./image/SPPF.png\" alt=\"图片描述\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db9c859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "#SPPF模块\n",
    "class SPPF(nn.Module):\n",
    "    def __init__(self, input_size, output_size, kernel_size=5, stride=1, padding=2):\n",
    "        super(SPPF, self).__init__()\n",
    "        self.conv1 = ConvBNSiLU(input_size, output_size=input_size // 2, kernel_size=1,stride=1,padding=0)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=5, stride=1, padding=2)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=5, stride=1, padding=2)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = ConvBNSiLU(2*input_size,output_size,kernel_size=1,stride=1,padding=0)\n",
    "          \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x1 = self.maxpool1(x)\n",
    "        x2 = self.maxpool2(x1)\n",
    "        x3 = self.maxpool3(x2)\n",
    "        # 拼接操作\n",
    "        out = torch.cat([x, x1, x2, x3], dim=1)\n",
    "        x4=self.conv2(out)\n",
    "        return x4\n",
    "\n",
    "# 测试代码\n",
    "# 输入数据示例，假设输入为batch_size=1, 通道数为1024，尺寸为20x20的特征图\n",
    "input_data = torch.randn(1, 1024,20,20)\n",
    "output_size=1024\n",
    "# 创建SPPF模块实例\n",
    "sppf_module = SPPF(1024 ,output_size)\n",
    "# 前向传播\n",
    "output = sppf_module(input_data)\n",
    "print(output.shape) \n",
    "\n",
    "# 输出符合图中预期"
   ]
  },
  {
   "cell_type": "code",
   "id": "404ceca4",
   "metadata": {},
   "outputs": [],
   "source": "# アップサンプリングモジュール(詳細はYOLOv5詳細説明を参照)\nimport torch\nimport torch.nn as nn\nclass Upsample(nn.Module):\n    def __init__(self, input_size, output_size, scale_factor=2):\n        super(Upsample, self).__init__()\n        # 畳み込み層でチャネル数を調整\n        self.conv = nn.Conv2d(input_size, output_size, kernel_size=1, stride=1, padding=0)\n        # アップサンプリング層\n        self.upsample = nn.Upsample(scale_factor=scale_factor, mode='nearest')\n\n    def forward(self, x):\n        # まず畳み込み操作でチャネル数を調整\n        x = self.conv(x)\n        # その後アップサンプリング操作を実行\n        x = self.upsample(x)\n        return x\n\n\n# テストコード\n\n# 入力を batch_size=1, 入力チャネル数が 256, 特徴マップサイズが 40x40 と仮定\ninput_tensor = torch.randn(1, 256, 40, 40)\n# アップサンプリングモジュールインスタンスを作成、入力チャネル数を256に変換、アップサンプリング倍数を2に設定\nupsample = Upsample(input_size=256, output_size=256, scale_factor=2)\n# 順伝播\noutput_tensor = upsample(input_tensor)\nprint(output_tensor.shape)\n\n#出力アップサンプリングは図中の期待値と一致"
  },
  {
   "cell_type": "markdown",
   "id": "5ba9886e",
   "metadata": {},
   "source": "# モジュール統合\n各モジュールの設計完了後、ネットワークをより簡潔に見せるため、以下のコードでは図中の各C3モジュールを封装し、以下がそのモジュール封装命名説明です\n## 命名説明\n図に示されているように\n![](./YOLOv5.png)\n行列のような方法でC3モジュールを命名します\n\n- 第1列には4つのC3モジュールがあり、上から下へそれぞれ：C11、C21、C31、C41と命名します\n- C3モジュール内の3を省略し、読書時の誤解を避けます",
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "55f84732",
   "metadata": {},
   "outputs": [],
   "source": "# C11モジュール、P1、P2、P3モジュールを含む\nclass C11(nn.Module):\n    def __init__(self, input_size=3, output_size=64, kernel_size=6, stride=2, padding=2):\n        super(C11, self).__init__()\n        #P1モジュール\n        self.P1=ConvBNSiLU(input_size=3,output_size=64,kernel_size=6,stride=2,padding=2)\n        #P2モジュール\n        self.P2=ConvBNSiLU(input_size=64,output_size=128,kernel_size=3,stride=2,padding=1)\n        \n        self.conv1 = ConvBNSiLU(input_size=128, output_size=64, kernel_size=1,stride=1,padding=0)\n        \n        self.bottle1=BottleNeck1(input_size=64,output_size=64,kernel_size=1,stride=1,padding=0)\n        self.bottle2=BottleNeck1(input_size=128,output_size=128,kernel_size=1,stride=1,padding=0)\n        self.bottle3=BottleNeck1(input_size=256,output_size=256,kernel_size=1,stride=1,padding=0)\n        \n        self.conv2 = ConvBNSiLU(input_size=128, output_size=64, kernel_size=1,stride=1,padding=0)\n        self.conv3 = ConvBNSiLU(input_size=576,output_size=128,kernel_size=1,stride=1,padding=0)\n        \n        #図中のP3を追加\n        \n        self.P3=ConvBNSiLU(input_size=128,output_size=256,kernel_size=3,stride=2,padding=1)\n        \n    def forward(self,x):\n        x=self.P1(x)\n        x=self.P2(x)\n        x1=self.conv1(x)\n        x2=self.conv2(x)\n        x1=self.bottle1(x1)\n        x1=self.bottle2(x1)\n        x1=self.bottle3(x1)\n        #print(f'pass 3 BottleNeck blocks is:{x1.shape}')\n        x3=torch.cat((x1,x2),dim=1)\n        x3=self.conv3(x3)\n        #print(f'C11 output is:{x3.shape}')\n        x3=self.P3(x3)\n        return x3\n\n# テストコード\n\ninput_tensor = torch.randn(1, 3, 640, 640)\n\nc11=C11(3,64,6,2,2)\n# 順伝播\noutput_tensor = c11(input_tensor)\nprint(output_tensor.shape)\n\n#出力アップサンプリングは図中の期待値と一致"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "573c0ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final output: torch.Size([1, 512, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "#C21模块\n",
    "class C21(nn.Module):\n",
    "    def __init__(self, input_size=256, output_size=128, kernel_size=1, stride=1, padding=0):\n",
    "        super(C21, self).__init__()\n",
    "        self.conv1 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n",
    "        \n",
    "        self.bottle1=BottleNeck1(input_size=128,output_size=128,kernel_size=1,stride=1,padding=0)\n",
    "        self.bottle2=BottleNeck1(2*output_size,2*output_size,kernel_size,stride,padding)\n",
    "        self.bottle3=BottleNeck1(4*output_size,4*output_size,kernel_size,stride,padding)\n",
    "        self.bottle4=BottleNeck1(8*output_size,8*output_size,kernel_size,stride,padding)\n",
    "        self.bottle5=BottleNeck1(16*output_size,16*output_size,kernel_size,stride,padding)\n",
    "        self.bottle6=BottleNeck1(32*output_size,32*output_size,kernel_size,stride,padding)\n",
    "        \n",
    "        self.conv2 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n",
    "        self.conv3 = ConvBNSiLU(input_size=65*128,output_size=256,kernel_size=1,stride=1,padding=0)\n",
    "        #65=32x2+1\n",
    "        \n",
    "        #加入P4模块\n",
    "        self.P4=ConvBNSiLU(input_size,output_size=512,kernel_size=3,stride=2,padding=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x1=self.conv1(x)\n",
    "        x2=self.conv2(x)\n",
    "        x1=self.bottle1(x1)\n",
    "        #print(f'pass 1 BottleNeck blocks is:{x1.shape}')\n",
    "        x1=self.bottle2(x1)\n",
    "        #print(f'pass 2 BottleNeck blocks is:{x1.shape}')\n",
    "        x1=self.bottle3(x1)\n",
    "        #print(f'pass 3 BottleNeck blocks is:{x1.shape}')\n",
    "        x1=self.bottle4(x1)\n",
    "        #print(f'pass 4 BottleNeck blocks is:{x1.shape}')\n",
    "        x1=self.bottle5(x1)\n",
    "        #print(f'pass 5 BottleNeck blocks is:{x1.shape}')\n",
    "        x1=self.bottle6(x1)\n",
    "        #print(f'pass 6 BottleNeck blocks is:{x1.shape}')\n",
    "        x3=torch.cat((x1,x2),dim=1)\n",
    "        x3=self.conv3(x3)\n",
    "        #print(f'C21 output is:{x3.shape}')\n",
    "        x4=self.P4(x3)\n",
    "        return x3,x4\n",
    "\n",
    "# 测试代码\n",
    "\n",
    "input_tensor = torch.randn(1, 256, 80, 80)\n",
    "\n",
    "c21=C21(256,128,1,1,0)\n",
    "# 前向传播\n",
    "output1,output_tensor2 = c21(input_tensor)\n",
    "print(f'final output: {output_tensor2.shape}')\n",
    "\n",
    "#输出上采样符合图中预期"
   ]
  },
  {
   "cell_type": "code",
   "id": "eead0b82",
   "metadata": {},
   "outputs": [],
   "source": "#C31モジュール 計算リソースが限られているため、ここではn=6の数量でデモを行います。計算リソースがある方はn=9を試してみてください\nclass C31(nn.Module):\n    def __init__(self, input_size=512, output_size=256, kernel_size=1, stride=1, padding=0):\n        super(C31, self).__init__()\n        self.conv1 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n        \n        self.bottle1=BottleNeck1(input_size=256,output_size=256,kernel_size=1,stride=1,padding=0)\n        self.bottle2=BottleNeck1(2*output_size,2*output_size,kernel_size,stride,padding)\n        self.bottle3=BottleNeck1(4*output_size,4*output_size,kernel_size,stride,padding)\n        self.bottle4=BottleNeck1(8*output_size,8*output_size,kernel_size,stride,padding)\n        self.bottle5=BottleNeck1(16*output_size,16*output_size,kernel_size,stride,padding)\n        self.bottle6=BottleNeck1(32*output_size,32*output_size,kernel_size,stride,padding)\n        \n        self.conv2 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n        self.conv3 = ConvBNSiLU(input_size=65*256,output_size=512,kernel_size=1,stride=1,padding=0)\n        #65=32x2+1\n        \n        #P5モジュールを追加\n        self.P5=ConvBNSiLU(input_size,output_size=1024,kernel_size=3,stride=2,padding=1)\n        \n    def forward(self,x):\n        x1=self.conv1(x)\n        x2=self.conv2(x)\n        x1=self.bottle1(x1)\n        #print(f'pass 1 BottleNeck blocks is:{x1.shape}')\n        x1=self.bottle2(x1)\n        #print(f'pass 2 BottleNeck blocks is:{x1.shape}')\n        x1=self.bottle3(x1)\n        #print(f'pass 3 BottleNeck blocks is:{x1.shape}')\n        x1=self.bottle4(x1)\n        #print(f'pass 4 BottleNeck blocks is:{x1.shape}')\n        x1=self.bottle5(x1)\n        #print(f'pass 5 BottleNeck blocks is:{x1.shape}')\n        x1=self.bottle6(x1)\n        #print(f'pass 6 BottleNeck blocks is:{x1.shape}')\n        x3=torch.cat((x1,x2),dim=1)\n        x3=self.conv3(x3)\n        #print(f'C21 output is:{x3.shape}')\n        x4=self.P5(x3)\n        return x3,x4\n\n# テストコード\n\ninput_tensor = torch.randn(1, 512, 40, 40)\n\nc31=C31(512,256,1,1,0)\n# 順伝播\noutput1,output_tensor2 = c31(input_tensor)\nprint(f'final output: {output_tensor2.shape}')\n\n#出力アップサンプリングは図中の期待値と一致"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "466f2b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "# C41模块,并且带有P3模块\n",
    "class C41(nn.Module):\n",
    "    def __init__(self, input_size=1024, output_size=512, kernel_size=1, stride=1, padding=0):\n",
    "        super(C41, self).__init__()\n",
    "        self.conv1 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n",
    "        self.bottle1=BottleNeck1(input_size=512,output_size=512,kernel_size=1,stride=1,padding=0)\n",
    "        self.bottle2=BottleNeck1(2*output_size,2*output_size,kernel_size,stride,padding)\n",
    "        self.bottle3=BottleNeck1(4*output_size,4*output_size,kernel_size,stride,padding)\n",
    "        \n",
    "        self.conv2 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n",
    "        self.conv3 = ConvBNSiLU(9*output_size,output_size=1024,kernel_size=1,stride=1,padding=0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x1=self.conv1(x)\n",
    "        x2=self.conv2(x)\n",
    "        x1=self.bottle1(x1)\n",
    "        x1=self.bottle2(x1)\n",
    "        x1=self.bottle3(x1)\n",
    "        #print(f'pass 3 BottleNeck blocks is:{x1.shape}')\n",
    "        x3=torch.cat((x1,x2),dim=1)\n",
    "        x3=self.conv3(x3)\n",
    "        return x3\n",
    "\n",
    "# 测试代码\n",
    "\n",
    "input_tensor = torch.randn(1, 1024, 20, 20)\n",
    "\n",
    "c41=C41(1024,512,1,1,0)\n",
    "# 前向传播\n",
    "output_tensor = c41(input_tensor)\n",
    "print(output_tensor.shape)\n",
    "\n",
    "#输出上采样符合图中预期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7734345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 80, 80])\n"
     ]
    }
   ],
   "source": [
    "#模块C12\n",
    "class C12(nn.Module):\n",
    "    def __init__(self, input_size=512, output_size=256, kernel_size=1, stride=1, padding=0):\n",
    "        super(C12, self).__init__()\n",
    "        self.conv1 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n",
    "        \n",
    "        self.bottle1=BottleNeck2(output_size,output_size,kernel_size,stride,padding)\n",
    "        self.bottle2=BottleNeck2(output_size,output_size,kernel_size,stride,padding)\n",
    "        self.bottle3=BottleNeck2(output_size,output_size,kernel_size,stride,padding)\n",
    "        \n",
    "        self.conv2 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n",
    "        self.conv3 = ConvBNSiLU(2*output_size,output_size=256,kernel_size=1,stride=1,padding=0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x1=self.conv1(x)\n",
    "        x2=self.conv2(x)\n",
    "        x1=self.bottle1(x1)\n",
    "        x1=self.bottle2(x1)\n",
    "        x1=self.bottle3(x1)\n",
    "        #print(f'pass 3 BottleNeck blocks is:{x1.shape}')\n",
    "        x3=torch.cat((x1,x2),dim=1)\n",
    "        x3=self.conv3(x3)\n",
    "        return x3\n",
    "\n",
    "# 测试代码\n",
    "\n",
    "input_tensor = torch.randn(1, 512, 80, 80)\n",
    "\n",
    "c12=C12(512,256,1,1,0)\n",
    "# 前向传播\n",
    "output_tensor = c12(input_tensor)\n",
    "print(output_tensor.shape)\n",
    "\n",
    "#输出上采样符合图中预期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2ba1183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "#模块C22\n",
    "class C22(nn.Module):\n",
    "    def __init__(self, input_size=1024, output_size=512, kernel_size=1, stride=1, padding=0):\n",
    "        super(C22, self).__init__()\n",
    "        self.conv1 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n",
    "        \n",
    "        self.bottle1=BottleNeck2(output_size,output_size,kernel_size,stride,padding)\n",
    "        self.bottle2=BottleNeck2(output_size,output_size,kernel_size,stride,padding)\n",
    "        self.bottle3=BottleNeck2(output_size,output_size,kernel_size,stride,padding)\n",
    "        \n",
    "        self.conv2 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n",
    "        self.conv3 = ConvBNSiLU(2*output_size,output_size=512,kernel_size=1,stride=1,padding=0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x1=self.conv1(x)\n",
    "        x2=self.conv2(x)\n",
    "        x1=self.bottle1(x1)\n",
    "        x1=self.bottle2(x1)\n",
    "        x1=self.bottle3(x1)\n",
    "        #print(f'pass 3 BottleNeck blocks is:{x1.shape}')\n",
    "        x3=torch.cat((x1,x2),dim=1)\n",
    "        x3=self.conv3(x3)\n",
    "        return x3\n",
    "\n",
    "# 测试代码\n",
    "\n",
    "input_tensor = torch.randn(1, 1024, 40, 40)\n",
    "\n",
    "c22=C22(1024,512,1,1,0)\n",
    "# 前向传播\n",
    "output_tensor = c22(input_tensor)\n",
    "print(output_tensor.shape)\n",
    "\n",
    "#输出上采样符合图中预期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe8d1107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 40, 40])\n"
     ]
    }
   ],
   "source": [
    "#模块C13\n",
    "class C13(nn.Module):\n",
    "    def __init__(self, input_size=512, output_size=256, kernel_size=1, stride=1, padding=0):\n",
    "        super(C13, self).__init__()\n",
    "        self.conv1 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n",
    "        \n",
    "        self.bottle1=BottleNeck2(output_size,output_size,kernel_size,stride,padding)\n",
    "        self.bottle2=BottleNeck2(output_size,output_size,kernel_size,stride,padding)\n",
    "        self.bottle3=BottleNeck2(output_size,output_size,kernel_size,stride,padding)\n",
    "        \n",
    "        self.conv2 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n",
    "        self.conv3 = ConvBNSiLU(input_size=512,output_size=512,kernel_size=1,stride=1,padding=0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x1=self.conv1(x)\n",
    "        x2=self.conv2(x)\n",
    "        x1=self.bottle1(x1)\n",
    "        x1=self.bottle2(x1)\n",
    "        x1=self.bottle3(x1)\n",
    "        #print(f'pass 3 BottleNeck blocks is:{x1.shape}')\n",
    "        x3=torch.cat((x1,x2),dim=1)\n",
    "        x3=self.conv3(x3)\n",
    "        return x3\n",
    "\n",
    "# 测试代码\n",
    "\n",
    "input_tensor = torch.randn(1, 512, 40, 40)\n",
    "\n",
    "c13=C13(512,256,1,1,0)\n",
    "# 前向传播\n",
    "output_tensor = c13(input_tensor)\n",
    "print(output_tensor.shape)\n",
    "\n",
    "#输出上采样符合图中预期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2bb5454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "#模块C23\n",
    "class C23(nn.Module):\n",
    "    def __init__(self, input_size=1024, output_size=512, kernel_size=1, stride=1, padding=0):\n",
    "        super(C23, self).__init__()\n",
    "        self.conv1 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n",
    "        \n",
    "        self.bottle1=BottleNeck2(output_size,output_size,kernel_size,stride,padding)\n",
    "        self.bottle2=BottleNeck2(output_size,output_size,kernel_size,stride,padding)\n",
    "        self.bottle3=BottleNeck2(output_size,output_size,kernel_size,stride,padding)\n",
    "        \n",
    "        self.conv2 = ConvBNSiLU(input_size, output_size, kernel_size,stride,padding)\n",
    "        self.conv3 = ConvBNSiLU(input_size=1024,output_size=1024,kernel_size=1,stride=1,padding=0)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x1=self.conv1(x)\n",
    "        x2=self.conv2(x)\n",
    "        x1=self.bottle1(x1)\n",
    "        x1=self.bottle2(x1)\n",
    "        x1=self.bottle3(x1)\n",
    "        #print(f'pass 3 BottleNeck blocks is:{x1.shape}')\n",
    "        x3=torch.cat((x1,x2),dim=1)\n",
    "        x3=self.conv3(x3)\n",
    "        return x3\n",
    "\n",
    "# 测试代码\n",
    "\n",
    "input_tensor = torch.randn(1, 1024, 20, 20)\n",
    "\n",
    "c23=C23(1024,512,1,1,0)\n",
    "# 前向传播\n",
    "output_tensor = c23(input_tensor)\n",
    "print(output_tensor.shape)\n",
    "\n",
    "#输出上采样符合图中预期"
   ]
  },
  {
   "cell_type": "code",
   "id": "1410c14b",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\n\n\nclass YOLOv5Config:\n    def __init__(self):\n        self.num_classes = 80  # クラス数\n        self.anchor_sizes = [[(10, 13), (16, 30), (33, 23)],  # 異なるスケールのアンカーボックスサイズ\n                          [(30, 61), (62, 45), (59, 119)],\n                          [(116, 90), (156, 198), (373, 326)]]\n        self.strides = [32, 16, 8]  # 異なるスケール特徴マップのストライド\n\n\n# 畳み込みブロックを定義、畳み込み、バッチ正規化、LeakyReLU活性化関数を含む\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super(ConvBlock, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.activation = nn.LeakyReLU(0.1)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.activation(x)\n        return x\n\n\n# ヘッドネットワーク予測モジュールを定義\nclass YOLOv5Head(nn.Module):\n    def __init__(self, config):\n        super(YOLOv5Head, self).__init__()\n        self.config = config\n        self.num_anchors_per_scale = len(config.anchor_sizes[0])\n        self.num_classes = config.num_classes\n\n        # 異なるスケールの予測層を構築\n        self.conv2d1 = ConvBlock(1024, 1024 * 2, 3, 1, 1)\n        self.conv2d2 = ConvBlock(1024 * 2, self.num_anchors_per_scale * (5 + self.num_classes), 1)\n        self.conv2d3 = ConvBlock(512, 512 * 2, 3, 1, 1)\n        self.conv2d4 = ConvBlock(512 * 2, self.num_anchors_per_scale * (5 + self.num_classes), 1)\n        self.conv2d5 = ConvBlock(256, 256 * 2, 3, 1, 1)\n        self.conv2d6 = ConvBlock(256 * 2, self.num_anchors_per_scale * (5 + self.num_classes), 1)\n\n    def forward(self, features):\n        \"\"\"\n        :param features: バックボーンネットワーク出力の異なるスケール特徴マップリスト、通常は3つのスケール\n        :return: 予測結果リスト、各要素は1つのスケールの予測に対応、形状は [batch_size, num_anchors * (5 + num_classes), grid_size, grid_size]\n        \"\"\"\n        predictions = []\n        # 第1のスケール\n        prediction = self.conv2d1(features[0])\n        prediction = self.conv2d2(prediction)\n        batch_size, _, grid_size1, _ = prediction.size()\n        # prediction = prediction.view(batch_size, self.num_anchors_per_scale, 5 + self.num_classes, grid_size1, grid_size1)\n        # prediction = prediction.permute(0, 1, 3, 4, 2)\n        prediction = prediction.view(batch_size, int(self.num_anchors_per_scale* (5 + self.num_classes)), grid_size1, grid_size1)\n        predictions.append(prediction)\n\n        # 第2のスケール\n        prediction = self.conv2d3(features[1])\n        prediction = self.conv2d4(prediction)\n        batch_size, _, grid_size2, _ = prediction.size()\n        # prediction = prediction.view(batch_size, self.num_anchors_per_scale, 5 + self.num_classes, grid_size2, grid_size2)\n        # prediction = prediction.permute(0, 1, 3, 4, 2)\n        prediction = prediction.view(batch_size, int(self.num_anchors_per_scale* (5 + self.num_classes)), grid_size2, grid_size2)\n        predictions.append(prediction)\n\n        # 第3のスケール\n        prediction = self.conv2d5(features[2])\n        prediction = self.conv2d6(prediction)\n        batch_size, _, grid_size3, _ = prediction.size()\n        # prediction = prediction.view(batch_size, self.num_anchors_per_scale, 5 + self.num_classes, grid_size3, grid_size3)\n        # prediction = prediction.permute(0, 1, 3, 4, 2)\n        prediction = prediction.view(batch_size, int(self.num_anchors_per_scale* (5 + self.num_classes)), grid_size3, grid_size3)\n   \n        predictions.append(prediction)\n\n        return predictions\n\n\n# 使用例\nif __name__ == \"__main__\":\n    # 設定を初期化\n    config = YOLOv5Config()\n    # 入力特徴マップを3つの異なるスケールと仮定、ここで形状を簡単にシミュレート\n    features = [torch.randn(1, 1024, 20, 20), torch.randn(1, 512, 40, 40), torch.randn(1, 256, 80, 80)]\n    model = YOLOv5Head(config)\n    predictions = model(features)\n    for i, prediction in enumerate(predictions):\n        print(f\"Scale {i + 1} prediction shape: {prediction.shape}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66e04184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#头部网络\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, input_size, output_size, kernel_size, stride, padding):\n",
    "        super(Conv,self).__init__()\n",
    "        self.conv=nn.Conv2d(input_size, output_size, kernel_size, stride, padding)\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a05199b",
   "metadata": {},
   "outputs": [],
   "source": "#次にモデルの構築を開始\n\nclass YOLOv5(nn.Module):\n    def __init__(self,input_size,output_size,kernel_size,stride,padding):\n        super(YOLOv5,self).__init__()\n        self.c11=C11(input_size=3, output_size=64, kernel_size=6, stride=2, padding=2)\n        self.c21=C21(input_size=256, output_size=128, kernel_size=1, stride=1, padding=0)\n        \n        self.c31=C31(input_size=512, output_size=256, kernel_size=1, stride=1, padding=0)\n        \n        self.c41=C41(input_size=1024, output_size=512, kernel_size=1, stride=1, padding=0)\n        \n        self.SPPF=SPPF(input_size=1024, output_size=1024, kernel_size=5, stride=1, padding=2)\n        \n        #図中第2列、記述順序は下から上、ConvBNSiLUモジュール命名規則は下から上で1から始まる\n        self.conv1=ConvBNSiLU(input_size=1024, output_size=512, kernel_size=1, stride=1, padding=0)\n        \n        self.up1=Upsample(input_size=512, output_size=512, scale_factor=2)\n        \n        self.c22=C22(input_size=1024, output_size=512, kernel_size=1, stride=1, padding=0)\n        self.conv2=ConvBNSiLU(input_size=512, output_size=256, kernel_size=1, stride=1, padding=0)\n        \n        self.up2=Upsample(input_size=256, output_size=256, scale_factor=2)\n        \n        self.c12=C12(input_size=512, output_size=256, kernel_size=1, stride=1, padding=0)\n\n        #図中第3列\n        self.conv3=ConvBNSiLU(input_size=256, output_size=256, kernel_size=3, stride=2, padding=1)\n\n        self.c13=C13(input_size=512, output_size=256, kernel_size=1, stride=1, padding=0)\n\n        self.conv4=ConvBNSiLU(input_size=512, output_size=512, kernel_size=3, stride=2, padding=1)\n\n        self.c23=C23(input_size=1024, output_size=512, kernel_size=1, stride=1, padding=0)\n        \n        #最終の畳み込みカーネル、n_clsはクラス数で、5+の後に直接クラス数を記述可能、サンプルコードのクラス数は80\n        #チャネル出力式：c=（5+n_cls）x3、ここで出力は（5+80）*3=255、上から下へそれぞれ1、2、3\n        self.Conv1=Conv(input_size=256, output_size=255, kernel_size=1, stride=1, padding=0)\n        \n        self.Conv2=Conv(input_size=512, output_size=255, kernel_size=1, stride=1, padding=0)\n        \n        self.Conv3=Conv(input_size=1024, output_size=255, kernel_size=1, stride=1, padding=0)\n    #テストコード    \n    def forward(self,x):\n        x=self.c11(x)\n        output1,x=self.c21(x)\n        output2,x=self.c31(x)\n        x=self.c41(x)\n        x=self.SPPF(x)\n        \n        x1=self.conv1(x)#分岐出力があり、マークする\n        \n        x=self.up1(x1)\n        x=torch.cat((x,output2),dim=1)\n        x=self.c22(x)\n        x2=self.conv2(x)#分岐出力があり、マークする\n        x=self.up2(x2)\n        x=torch.cat((x,output1),dim=1)\n        final_output1=self.c12(x)#分岐出力があり、マークする\n        \n        x=self.conv3(final_output1)\n        \n        x=torch.cat((x,x2),dim=1)\n        final_output2=self.c13(x)\n        \n        x=self.conv4(final_output2)\n        x=torch.cat((x,x1),dim=1)\n        \n        final_output3=self.c23(x)\n        \n        final_output1=self.Conv1(final_output1)\n        final_output2=self.Conv2(final_output2)\n        final_output3=self.Conv3(final_output3)\n        \n        return final_output1,final_output2,final_output3\n\n\n# テストコード\ninput_tensor = torch.randn(1, 3, 640, 640)\n# 順伝播\nyolov5=YOLOv5(3,64,6,2,2)\noutput_1,output_2,output_3 = yolov5(input_tensor)\nprint(output_1.shape)\nprint(output_2.shape)\nprint(output_3.shape)\n#出力アップサンプリングは図中の期待値と一致 \nprint(output_1)\nprint(output_2)\nprint(output_3)"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c67a96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fused feature map 1 shape: torch.Size([1, 255, 80, 80])\n",
      "Fused feature map 1 tensor: tensor([[[[-0.0309, -0.0648, -0.0771,  ..., -0.0580, -0.1567, -0.1000],\n",
      "          [-0.1346, -0.1231, -0.2336,  ..., -0.0989,  0.0141, -0.1184],\n",
      "          [-0.0729, -0.0732, -0.0919,  ...,  0.0997, -0.0691, -0.0659],\n",
      "          ...,\n",
      "          [-0.0431, -0.1052, -0.0916,  ..., -0.0715, -0.0924, -0.0861],\n",
      "          [-0.0068, -0.1175, -0.0900,  ..., -0.0375, -0.1245,  0.0005],\n",
      "          [-0.0206, -0.0479, -0.0649,  ..., -0.0866, -0.1584, -0.1003]],\n",
      "\n",
      "         [[ 0.0088, -0.0038,  0.0220,  ...,  0.1175, -0.0582,  0.0062],\n",
      "          [ 0.0516, -0.0150,  0.0134,  ..., -0.0050,  0.1025, -0.0260],\n",
      "          [-0.0165,  0.0262,  0.0409,  ..., -0.0104, -0.1004, -0.0141],\n",
      "          ...,\n",
      "          [ 0.0305,  0.0322, -0.0217,  ...,  0.0755, -0.0186, -0.0485],\n",
      "          [ 0.0181, -0.0721, -0.0223,  ..., -0.0173, -0.0760,  0.0109],\n",
      "          [-0.0059, -0.0110,  0.0185,  ..., -0.0223, -0.0538, -0.0657]],\n",
      "\n",
      "         [[ 0.0265,  0.0174,  0.0596,  ...,  0.0712,  0.0090, -0.0078],\n",
      "          [ 0.0013, -0.0378,  0.1063,  ...,  0.0517,  0.0851,  0.0760],\n",
      "          [-0.0309,  0.0112,  0.0601,  ...,  0.1410,  0.1183,  0.0497],\n",
      "          ...,\n",
      "          [ 0.0291,  0.0061,  0.0601,  ...,  0.0323,  0.1597,  0.1042],\n",
      "          [-0.0025,  0.0141,  0.0298,  ...,  0.0608,  0.0598,  0.1154],\n",
      "          [-0.0091,  0.0151,  0.0656,  ...,  0.0754,  0.0719,  0.1028]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0342,  0.0689,  0.0488,  ...,  0.0530,  0.0245,  0.0168],\n",
      "          [-0.0221,  0.0084,  0.0358,  ...,  0.0511,  0.0099,  0.0701],\n",
      "          [ 0.0005, -0.0012, -0.0419,  ..., -0.0391, -0.0672,  0.0786],\n",
      "          ...,\n",
      "          [ 0.0114,  0.0330,  0.1208,  ...,  0.1513,  0.0760,  0.0009],\n",
      "          [ 0.0053,  0.0109,  0.1066,  ..., -0.0611,  0.0249, -0.0824],\n",
      "          [-0.0168, -0.0122,  0.0325,  ...,  0.0022,  0.0273,  0.0057]],\n",
      "\n",
      "         [[-0.0072,  0.0010, -0.0075,  ...,  0.0197, -0.0071, -0.0145],\n",
      "          [-0.0166,  0.0121, -0.0084,  ..., -0.0188, -0.0427, -0.0063],\n",
      "          [-0.0344, -0.0580,  0.0414,  ...,  0.0265,  0.0162, -0.0584],\n",
      "          ...,\n",
      "          [-0.0041, -0.0175,  0.0738,  ..., -0.0437, -0.0257,  0.0110],\n",
      "          [ 0.0450,  0.0090,  0.0710,  ..., -0.0878,  0.0924, -0.0039],\n",
      "          [-0.0052,  0.0143, -0.0584,  ..., -0.0191,  0.0023, -0.0303]],\n",
      "\n",
      "         [[-0.0262,  0.0101,  0.0031,  ..., -0.0235, -0.0844, -0.0331],\n",
      "          [-0.0337, -0.0500, -0.0893,  ..., -0.0948,  0.0474, -0.0924],\n",
      "          [-0.1407, -0.0841, -0.1688,  ..., -0.0248, -0.0742,  0.0511],\n",
      "          ...,\n",
      "          [-0.0440, -0.0021, -0.0237,  ...,  0.0823,  0.0151, -0.0831],\n",
      "          [-0.0593,  0.0817,  0.0560,  ..., -0.0047,  0.1049, -0.0280],\n",
      "          [ 0.0068,  0.0086, -0.0564,  ..., -0.0429, -0.0667, -0.0366]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "Fused feature map 2 shape: torch.Size([1, 255, 40, 40])\n",
      "Fused feature map 2 tensor: tensor([[[[ 5.3611e-02,  3.9086e-02,  1.0794e-01,  ...,  9.4377e-03,\n",
      "            1.5723e-02, -1.9438e-02],\n",
      "          [-5.0780e-03, -6.7142e-03, -5.6795e-02,  ..., -2.7391e-02,\n",
      "           -6.7493e-02, -4.5137e-02],\n",
      "          [ 2.4111e-03,  1.4357e-02,  2.9992e-02,  ...,  4.3337e-02,\n",
      "            2.6513e-02, -6.6237e-02],\n",
      "          ...,\n",
      "          [ 4.9921e-02, -4.7496e-02,  3.2494e-03,  ..., -4.6897e-02,\n",
      "           -1.4172e-02, -9.1933e-02],\n",
      "          [ 6.1642e-02,  8.8563e-02,  3.3184e-01,  ..., -6.6390e-02,\n",
      "            3.1119e-02, -7.6609e-02],\n",
      "          [ 4.1872e-02, -7.0051e-05, -3.4293e-02,  ...,  2.4360e-03,\n",
      "            1.7692e-02, -6.9138e-02]],\n",
      "\n",
      "         [[-6.0226e-02, -2.1831e-02,  7.8524e-02,  ...,  8.0188e-02,\n",
      "            2.5521e-02,  1.7502e-02],\n",
      "          [-7.1136e-02, -1.7160e-02,  1.0782e-01,  ...,  6.0549e-02,\n",
      "            7.8657e-02,  2.2074e-02],\n",
      "          [ 3.2836e-02,  7.3785e-02,  1.5833e-01,  ...,  3.2720e-02,\n",
      "            6.2643e-02,  1.2336e-01],\n",
      "          ...,\n",
      "          [-1.1688e-01, -7.6177e-02,  3.1751e-02,  ...,  6.3532e-02,\n",
      "            8.3707e-02,  7.8351e-02],\n",
      "          [-7.7479e-02,  5.6725e-02,  2.0893e-02,  ...,  1.0358e-01,\n",
      "            6.8572e-02,  6.8673e-02],\n",
      "          [-4.1020e-02, -2.6028e-02,  4.4700e-02,  ...,  1.0168e-01,\n",
      "            6.0096e-02,  4.3894e-02]],\n",
      "\n",
      "         [[ 2.5576e-02, -3.3708e-02,  4.1824e-03,  ..., -1.0185e-02,\n",
      "            6.0172e-02, -2.3098e-02],\n",
      "          [ 9.2037e-02,  8.8715e-02,  1.5639e-01,  ...,  1.0875e-01,\n",
      "            1.0515e-01,  4.1440e-02],\n",
      "          [ 3.9054e-02,  1.1538e-01,  5.7253e-02,  ...,  2.7834e-02,\n",
      "            6.6106e-02,  5.5295e-02],\n",
      "          ...,\n",
      "          [ 1.2397e-01,  4.2588e-02, -1.2022e-01,  ..., -9.3096e-04,\n",
      "            7.1853e-02,  7.6113e-02],\n",
      "          [ 3.4277e-02,  1.5681e-02,  1.3709e-01,  ...,  6.1431e-02,\n",
      "            7.4946e-02,  2.6973e-02],\n",
      "          [ 3.3429e-02,  2.6547e-02,  1.3498e-01,  ...,  3.9261e-02,\n",
      "            2.7514e-02,  4.2381e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.1939e-03, -1.4392e-02, -4.1247e-02,  ..., -1.2837e-01,\n",
      "           -3.1458e-02, -4.9874e-02],\n",
      "          [-1.2742e-02, -4.7336e-02, -5.6777e-02,  ..., -1.7815e-02,\n",
      "            4.9824e-03, -8.1967e-03],\n",
      "          [-1.6216e-02, -9.7029e-02, -8.6471e-02,  ..., -5.3791e-02,\n",
      "           -7.9366e-02, -4.7546e-02],\n",
      "          ...,\n",
      "          [-1.7501e-02, -1.1177e-01, -3.8975e-02,  ..., -3.7998e-02,\n",
      "           -1.3848e-01, -5.4676e-02],\n",
      "          [-8.0014e-02, -1.0382e-01, -7.1483e-02,  ..., -5.0613e-02,\n",
      "           -4.3020e-02, -2.7923e-02],\n",
      "          [ 6.7065e-03, -1.1832e-01, -9.1423e-02,  ..., -8.9945e-02,\n",
      "           -6.8178e-02, -8.1657e-02]],\n",
      "\n",
      "         [[-3.2480e-02,  1.5035e-02, -2.2133e-02,  ..., -5.1540e-02,\n",
      "           -1.8264e-02,  2.0966e-02],\n",
      "          [-2.4939e-02, -1.2186e-01,  1.6668e-02,  ..., -5.8454e-02,\n",
      "           -4.7999e-02, -4.2434e-03],\n",
      "          [-7.3397e-02, -5.5306e-02, -5.0069e-02,  ...,  8.9936e-03,\n",
      "           -2.7851e-02, -1.3943e-02],\n",
      "          ...,\n",
      "          [-3.0094e-02,  3.6757e-02,  3.1535e-01,  ...,  1.0734e-02,\n",
      "           -5.1224e-02,  2.4401e-02],\n",
      "          [ 4.2051e-02,  3.7053e-03,  1.6377e-01,  ...,  8.7071e-02,\n",
      "            4.3734e-02,  1.1308e-02],\n",
      "          [ 6.9641e-03,  1.5627e-02,  4.5503e-03,  ..., -9.7645e-03,\n",
      "            5.7005e-02,  1.6742e-02]],\n",
      "\n",
      "         [[ 3.6512e-02,  4.6931e-02,  4.0236e-02,  ...,  8.3536e-03,\n",
      "            5.0699e-02, -3.6320e-03],\n",
      "          [-2.9832e-02,  3.4332e-03,  2.1312e-02,  ...,  3.7080e-02,\n",
      "           -1.3352e-02, -1.0530e-01],\n",
      "          [-3.7415e-02, -6.7275e-02, -3.0450e-04,  ..., -2.3663e-02,\n",
      "           -5.0032e-02, -7.4046e-02],\n",
      "          ...,\n",
      "          [ 6.8104e-02,  9.1032e-02, -2.2850e-02,  ...,  3.6505e-02,\n",
      "            1.7075e-03, -2.0611e-02],\n",
      "          [ 4.6805e-02,  1.6580e-02, -5.2364e-02,  ..., -2.3865e-02,\n",
      "            1.2065e-02, -3.6179e-02],\n",
      "          [-9.2629e-03, -1.0574e-02,  1.9559e-02,  ...,  1.6124e-02,\n",
      "           -3.2182e-02, -2.6831e-02]]]], grad_fn=<ConvolutionBackward0>)\n",
      "Fused feature map 3 shape: torch.Size([1, 255, 20, 20])\n",
      "Fused feature map 3 tensor: tensor([[[[ 0.0285,  0.0932,  0.0363,  ...,  0.0034,  0.0246, -0.0153],\n",
      "          [ 0.0618,  0.0429, -0.1331,  ..., -0.0491, -0.0506, -0.0269],\n",
      "          [ 0.0377,  0.1651, -0.1002,  ...,  0.0091,  0.0041, -0.0054],\n",
      "          ...,\n",
      "          [-0.1136, -0.1419,  0.1250,  ...,  0.1201,  0.1562,  0.0075],\n",
      "          [-0.0452, -0.0658, -0.0947,  ...,  0.0232,  0.0108, -0.0613],\n",
      "          [-0.0249,  0.0265,  0.0446,  ...,  0.0288,  0.0454, -0.0370]],\n",
      "\n",
      "         [[ 0.0966,  0.0510,  0.1252,  ...,  0.0564,  0.0217, -0.0016],\n",
      "          [-0.0158,  0.1084, -0.0094,  ...,  0.0808,  0.1085, -0.0044],\n",
      "          [-0.0497,  0.0931,  0.3600,  ...,  0.0567,  0.0417, -0.0038],\n",
      "          ...,\n",
      "          [ 0.0640, -0.0216, -0.0398,  ...,  0.0830,  0.1231,  0.1084],\n",
      "          [ 0.0529,  0.0414, -0.0014,  ..., -0.0121,  0.0435,  0.0444],\n",
      "          [ 0.0418,  0.1286,  0.0221,  ...,  0.0660,  0.0918,  0.0572]],\n",
      "\n",
      "         [[-0.0169, -0.1325, -0.0928,  ..., -0.0694, -0.0778, -0.0252],\n",
      "          [-0.0773,  0.0153, -0.1198,  ..., -0.1392, -0.0415, -0.0353],\n",
      "          [-0.1822, -0.0567, -0.1944,  ..., -0.1185, -0.0929, -0.1071],\n",
      "          ...,\n",
      "          [ 0.0852,  0.0368, -0.1144,  ...,  0.0184, -0.0044, -0.0133],\n",
      "          [ 0.1340, -0.0588,  0.0097,  ...,  0.0073,  0.0645, -0.0988],\n",
      "          [ 0.0545,  0.0768,  0.0977,  ..., -0.0273, -0.0238, -0.0058]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0150, -0.1325, -0.0886,  ...,  0.0102,  0.0453,  0.0278],\n",
      "          [-0.0396, -0.1156,  0.0597,  ...,  0.0538,  0.0307,  0.0338],\n",
      "          [-0.0690,  0.0183, -0.2024,  ...,  0.0433,  0.0237,  0.0028],\n",
      "          ...,\n",
      "          [-0.0829,  0.0023,  0.0129,  ..., -0.0414, -0.0837,  0.0119],\n",
      "          [-0.0221, -0.0549, -0.0155,  ..., -0.0413, -0.0061, -0.0298],\n",
      "          [-0.0621,  0.0184,  0.0148,  ...,  0.0261, -0.0418, -0.0236]],\n",
      "\n",
      "         [[ 0.0237, -0.0301,  0.0087,  ...,  0.0271,  0.0460,  0.0714],\n",
      "          [ 0.0276,  0.0716,  0.0422,  ..., -0.0295, -0.0098,  0.0942],\n",
      "          [ 0.0989,  0.0114,  0.1987,  ..., -0.0235,  0.0025,  0.0649],\n",
      "          ...,\n",
      "          [-0.0147,  0.0962,  0.0390,  ..., -0.0729,  0.0394,  0.0268],\n",
      "          [-0.0467,  0.0119, -0.0105,  ...,  0.0316, -0.0261,  0.0550],\n",
      "          [-0.0484,  0.0731,  0.0530,  ...,  0.0169,  0.0495,  0.0832]],\n",
      "\n",
      "         [[ 0.0153, -0.0713, -0.0210,  ...,  0.0920,  0.0068, -0.0573],\n",
      "          [-0.0917, -0.0688, -0.0831,  ...,  0.0549,  0.0985, -0.0036],\n",
      "          [-0.0454, -0.0951, -0.0086,  ...,  0.0886,  0.0757,  0.0071],\n",
      "          ...,\n",
      "          [ 0.0320,  0.0167, -0.0124,  ...,  0.0300,  0.0276, -0.0241],\n",
      "          [-0.0066, -0.0360, -0.1919,  ..., -0.1180, -0.0173, -0.0053],\n",
      "          [ 0.0687,  0.0506, -0.0298,  ..., -0.0309, -0.0232, -0.0767]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeaturePyramidFusion(nn.Module):\n",
    "    def __init__(self, in_channels_list, out_channels):\n",
    "        \"\"\"\n",
    "        初始化特征金字塔融合模块。\n",
    "\n",
    "        参数:\n",
    "        in_channels_list (list): 输入特征图的通道数列表，列表长度表示有多少个不同尺度的特征图输入。\n",
    "        out_channels (int): 输出特征图的通道数，所有输出特征图的通道数将统一为该值。\n",
    "        \"\"\"\n",
    "        super(FeaturePyramidFusion, self).__init__()\n",
    "        self.num_features = len(in_channels_list)  # 输入特征图的数量\n",
    "        # 为每个输入特征图创建一个1x1卷积层，用于调整通道数\n",
    "        self.conv1x1_modules = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "            for in_channels in in_channels_list\n",
    "        ])\n",
    "        # 用于上采样的最近邻插值\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        # 用于融合后的3x3卷积层\n",
    "        self.conv3x3_modules = nn.ModuleList([\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "            for _ in range(self.num_features)\n",
    "        ])\n",
    "\n",
    "    def forward(self, feature_maps):\n",
    "        \"\"\"\n",
    "        前向传播函数，实现特征金字塔的融合过程。\n",
    "\n",
    "        参数:\n",
    "        feature_maps (list): 输入的不同尺度的特征图列表，列表中的元素顺序应与初始化时的in_channels_list对应。\n",
    "\n",
    "        返回:\n",
    "        list: 融合后的特征图列表，与输入特征图列表长度相同。\n",
    "        \"\"\"\n",
    "        # 检查输入特征图的数量和通道数是否与初始化时一致\n",
    "        if len(feature_maps) != self.num_features:\n",
    "            raise ValueError(f\"Expected {self.num_features} feature maps, but got {len(feature_maps)}\")\n",
    "        for i, feature_map in enumerate(feature_maps):\n",
    "            if feature_map.shape[1] != list(self.conv1x1_modules[i].parameters())[0].shape[1]:\n",
    "                raise ValueError(f\"Expected input feature map {i} to have {list(self.conv1x1_modules[i].parameters())[0].shape[1]} channels, but got {feature_map.shape[1]}\")\n",
    "\n",
    "        # 首先将输入特征图的通道数调整为统一的out_channels\n",
    "        adjusted_feature_maps = []\n",
    "        for i in range(self.num_features):\n",
    "            adjusted_feature_maps.append(self.conv1x1_modules[i](feature_maps[i]))\n",
    "\n",
    "        # 从最高分辨率的特征图开始，依次进行上采样和融合\n",
    "        fused_feature_maps = []\n",
    "        for i in range(self.num_features - 1, -1, -1):\n",
    "            if i == self.num_features - 1:\n",
    "                # 最高分辨率的特征图直接使用调整后的特征图\n",
    "                x = adjusted_feature_maps[i]\n",
    "            else:\n",
    "                # 上采样上一层的融合结果\n",
    "                upsampled_features = self.upsample(fused_feature_maps[-1])\n",
    "                # 与当前层的调整后特征图进行元素相加\n",
    "                x = adjusted_feature_maps[i] + upsampled_features\n",
    "            # 通过3x3卷积进一步融合特征\n",
    "            x = self.conv3x3_modules[i](x)\n",
    "            fused_feature_maps.append(x)\n",
    "\n",
    "        # 反转融合特征图列表，使其与输入特征图列表的尺度顺序一致\n",
    "        return fused_feature_maps[::-1]\n",
    "\n",
    "# 示例输入，这里需要确保output_1, output_2, output_3的通道数与in_channels_list对应\n",
    "\n",
    "feature_maps = [output_1, output_2, output_3]\n",
    "in_channels_list = [255, 255, 255]\n",
    "out_channels = 255\n",
    "\n",
    "#创建特征金字塔融合模块\n",
    "fpn = FeaturePyramidFusion(in_channels_list, out_channels)\n",
    "#进行特征融合\n",
    "fused_features = fpn(feature_maps)\n",
    "\n",
    "#打印融合后特征图的形状\n",
    "for i, feature in enumerate(fused_features):\n",
    "    print(f\"Fused feature map {i + 1} shape: {feature.shape}\")\n",
    "    print(f\"Fused feature map {i + 1} tensor: {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e50a4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv5(\n",
      "  (c11): C11(\n",
      "    (P1): ConvBNSiLU(\n",
      "      (conv): Conv2d(3, 64, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (P2): ConvBNSiLU(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (conv1): ConvBNSiLU(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (bottle1): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle2): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle3): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (conv2): ConvBNSiLU(\n",
      "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (conv3): ConvBNSiLU(\n",
      "      (conv): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (P3): ConvBNSiLU(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (c21): C21(\n",
      "    (conv1): ConvBNSiLU(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (bottle1): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle2): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle3): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle4): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle5): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle6): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (conv2): ConvBNSiLU(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (conv3): ConvBNSiLU(\n",
      "      (conv): Conv2d(8320, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (P4): ConvBNSiLU(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (c31): C31(\n",
      "    (conv1): ConvBNSiLU(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (bottle1): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle2): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle3): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle4): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle5): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(4096, 4096, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle6): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(8192, 8192, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(8192, 8192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (conv2): ConvBNSiLU(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (conv3): ConvBNSiLU(\n",
      "      (conv): Conv2d(16640, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (P5): ConvBNSiLU(\n",
      "      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (c41): C41(\n",
      "    (conv1): ConvBNSiLU(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (bottle1): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle2): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle3): BottleNeck1(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (conv2): ConvBNSiLU(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (conv3): ConvBNSiLU(\n",
      "      (conv): Conv2d(4608, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (SPPF): SPPF(\n",
      "    (conv1): ConvBNSiLU(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (maxpool1): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    (maxpool2): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    (maxpool3): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    (conv2): ConvBNSiLU(\n",
      "      (conv): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (conv1): ConvBNSiLU(\n",
      "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (up1): Upsample(\n",
      "    (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
      "  )\n",
      "  (c22): C22(\n",
      "    (conv1): ConvBNSiLU(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (bottle1): BottleNeck2(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle2): BottleNeck2(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle3): BottleNeck2(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (conv2): ConvBNSiLU(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (conv3): ConvBNSiLU(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (conv2): ConvBNSiLU(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (up2): Upsample(\n",
      "    (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (upsample): Upsample(scale_factor=2.0, mode='nearest')\n",
      "  )\n",
      "  (c12): C12(\n",
      "    (conv1): ConvBNSiLU(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (bottle1): BottleNeck2(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle2): BottleNeck2(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle3): BottleNeck2(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (conv2): ConvBNSiLU(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (conv3): ConvBNSiLU(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (conv3): ConvBNSiLU(\n",
      "    (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (c13): C13(\n",
      "    (conv1): ConvBNSiLU(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (bottle1): BottleNeck2(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle2): BottleNeck2(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle3): BottleNeck2(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (conv2): ConvBNSiLU(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (conv3): ConvBNSiLU(\n",
      "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (conv4): ConvBNSiLU(\n",
      "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (c23): C23(\n",
      "    (conv1): ConvBNSiLU(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (bottle1): BottleNeck2(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle2): BottleNeck2(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (bottle3): BottleNeck2(\n",
      "      (conv1): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (conv2): ConvBNSiLU(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (conv2): ConvBNSiLU(\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "    (conv3): ConvBNSiLU(\n",
      "      (conv): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (Conv1): Conv(\n",
      "    (conv): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (Conv2): Conv(\n",
      "    (conv): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (Conv3): Conv(\n",
      "    (conv): Conv2d(1024, 255, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=YOLOv5(3,64,6,2,2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "id": "4903d043",
   "metadata": {},
   "outputs": [],
   "source": "# 以下は未完成です、readmeドキュメントを参照してください\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# YOLOv5の損失関数クラスを定義\nclass YOLOv5Loss(nn.Module):\n    def __init__(self, num_classes, lambda_coord=5, lambda_noobj=0.5):\n        super(YOLOv5Loss, self).__init__()\n        self.num_classes = num_classes\n        self.lambda_coord = lambda_coord\n        self.lambda_noobj = lambda_noobj\n        self.num_anchors = 3  # 各位置のアンカーボックス数\n\n    def forward(self, output1, output2, output3, targets1, targets2, targets3):\n        # 損失を初期化\n        loss = 0\n        \n        # 第1の出力を処理\n        # 各アンカーボックスの予測を処理するため次元を調整\n        obj_preds1 = output1[..., 4::(5 + self.num_classes)].unsqueeze(-1)  # ターゲット信頼度予測\n        class_preds1 = output1[..., 5:(5 + self.num_classes)]  # クラス予測\n        box_preds1 = output1[..., :4]  # バウンディングボックス予測\n\n        # 各アンカーボックスの真値を処理するため次元を調整\n        obj_targets1 = targets1[..., 4::(5 + self.num_classes)].unsqueeze(-1)  # ターゲット信頼度真値\n        class_targets1 = targets1[..., 5:(5 + self.num_classes)]  # クラス真値\n        box_targets1 = targets1[..., :4]  # バウンディングボックス真値\n\n        # ターゲット信頼度損失を計算（二項交差エントロピー損失を使用）\n        obj_loss1 = F.binary_cross_entropy_with_logits(obj_preds1, obj_targets1, reduction='none')\n\n        # 分類損失を計算（交差エントロピー損失を使用）\n        ## class_loss3, class_loss2 もpermuteオペレーションを削除、Hong\n        # class_loss1 = F.cross_entropy(class_preds1.permute(0, 2, 1), class_targets1.permute(0, 2, 1), reduction='none')\n        class_loss1 = F.cross_entropy(class_preds1, class_targets1, reduction='none')\n\n        # バウンディングボックス損失を計算（平均二乗誤差損失を使用）\n        # ターゲットがある位置について、バウンディングボックスの損失を計算\n        coord_mask1 = obj_targets1 > 0\n        box_loss1 = F.mse_loss(box_preds1[coord_mask1], box_targets1[coord_mask1], reduction='none')\n\n        # 第1の出力の総損失を計算\n        loss1 = (obj_loss1 * (obj_targets1 > 0).float() * (class_loss1 + self.lambda_coord * box_loss1) +\n                 self.lambda_noobj * obj_loss1 * (obj_targets1 == 0).float()).sum()\n\n        # 第2の出力を処理（第1の出力と同様の処理）\n        obj_preds2 = output2[..., 4::(5 + self.num_classes)].unsqueeze(-1)\n        class_preds2 = output2[..., 5:(5 + self.num_classes)]\n        box_preds2 = output2[..., :4]\n\n        obj_targets2 = targets2[..., 4::(5 + self.num_classes)].unsqueeze(-1)\n        class_targets2 = targets2[..., 5:(5 + self.num_classes)]\n        box_targets2 = targets2[..., :4]\n\n        obj_loss2 = F.binary_cross_entropy_with_logits(obj_preds2, obj_targets2, reduction='none')\n        class_loss2 = F.cross_entropy(class_preds2, class_targets2, reduction='none')\n        coord_mask2 = obj_targets2 > 0\n        box_loss2 = F.mse_loss(box_preds2[coord_mask2], box_targets2[coord_mask2], reduction='none')\n\n        loss2 = (obj_loss2 * (obj_targets2 > 0).float() * (class_loss2 + self.lambda_coord * box_loss2) +\n                 self.lambda_noobj * obj_loss2 * (obj_targets2 == 0).float()).sum()\n\n        # 第3の出力を処理（第1の出力と同様の処理）\n        obj_preds3 = output3[..., 4::(5 + self.num_classes)].unsqueeze(-1)\n        class_preds3 = output3[..., 5:(5 + self.num_classes)]\n        box_preds3 = output3[..., :4]\n\n        obj_targets3 = targets3[..., 4::(5 + self.num_classes)].unsqueeze(-1)\n        class_targets3 = targets3[..., 5:(5 + self.num_classes)]\n        box_targets3 = targets3[..., :4]\n\n        obj_loss3 = F.binary_cross_entropy_with_logits(obj_preds3, obj_targets3, reduction='none')\n        class_loss3 = F.cross_entropy(class_preds3, class_targets3, reduction='none')\n        coord_mask3 = obj_targets3 > 0\n        box_loss3 = F.mse_loss(box_preds3[coord_mask3], box_targets3[coord_mask3], reduction='none')\n\n        loss3 = (obj_loss3 * (obj_targets3 > 0).float() * (class_loss3 + self.lambda_coord * box_loss3) +\n                 self.lambda_noobj * obj_loss3 * (obj_targets3 == 0).float()).sum()\n\n        # 総損失は3つの出力の損失の合計\n        loss = loss1 + loss2 + loss3\n\n        return loss"
  },
  {
   "cell_type": "code",
   "id": "c7d55b31",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n\ndef train(model, train_loader, loss_fn, optimizer, device, save_path='yolov5_model.pt', num_epochs=8):\n    model.train()  # モデルを訓練モードに設定\n    for epoch in range(num_epochs):\n        total_loss = 0.0\n        num_batches = 0\n        num_classes = 80\n        for batch_idx, (images, labels) in enumerate(train_loader):\n            images = images.to(device)\n\n            # モデル順伝播\n            output1, output2, output3 = model(images)\n\n            batch_loss = 0\n            for i in range(len(labels)):\n                label = labels[i].to(device)\n                num_objects = label.size(0)\n                num_anchors = 3\n                num_classes = loss_fn.num_classes\n\n                # 損失関数の期待入力に合わせてラベル形状を調整\n                target1 = torch.zeros((1, num_anchors, num_classes + 5, 80, 80)).to(device)\n                target1[..., 5:(5 + num_classes), :num_objects, :num_objects] = torch.ones((num_classes, num_objects, num_objects))\n                target1 = target1.view((1, int(num_anchors*(num_classes + 5)), 80, 80))\n\n                target2 = torch.zeros((1, num_anchors, num_classes + 5, 40, 40)).to(device)\n                target2[..., 5:(5 + num_classes), :num_objects, :num_objects] = torch.ones((num_classes, num_objects, num_objects))\n                target2 = target2.view((1, int(num_anchors*(num_classes + 5)), 40, 40))\n\n                target3 = torch.zeros((1, num_anchors, num_classes + 5, 20, 20)).to(device)\n                target3[..., 5:(5 + num_classes), :num_objects, :num_objects] = torch.ones((num_classes, num_objects, num_objects))\n                target3 = target3.view((1, int(num_anchors*(num_classes + 5)), 20, 20))\n\n                # 損失を計算\n                loss = loss_fn(output1[i].unsqueeze(0), output2[i].unsqueeze(0), output3[i].unsqueeze(0),\n                             target1, target2, target3)\n                batch_loss += loss\n\n            optimizer.zero_grad()  # 勾配をゼロクリア\n            batch_loss.backward()  # 逆伝播\n            optimizer.step()  # オプティマイザー更新\n\n            total_loss += batch_loss.item()\n            num_batches += 1\n\n            if (batch_idx + 1) % 10 == 0:\n                avg_loss = total_loss / num_batches\n                print(f\"Epoch {epoch + 1}, Batch {batch_idx + 1}: Average Loss = {avg_loss}\")\n                total_loss = 0.0\n                num_batches = 0\n\n    # モデルを保存\n    torch.save(model.state_dict(), save_path)\n    print(f\"Model saved to {save_path}\")\n\ndef main():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    num_classes = 80\n    # モデルを初期化\n    model = YOLOv5(3, 64, 6, 2, 2)\n    model.to(device)\n    # 損失関数を定義\n    loss_fn = YOLOv5Loss(num_classes=80,lambda_coord=5, lambda_noobj=0.5)\n    # オプティマイザーを定義\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n    # データセットとデータローダーを作成\n    train_dataset = YOLODataset(train_image_dir, train_label_dir, img_size=(640, 640), classes=classes)\n    train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate_fn)\n    # 訓練関数を呼び出し\n    train(model, train_dataloader, loss_fn, optimizer, device)\n\n\nif __name__ == \"__main__\":\n    main()"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0566a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "\n",
    "# def test(model, test_loader, loss_fn, device):\n",
    "#     model.eval()  # 模型设置为评估模式\n",
    "#     total_loss = 0.0\n",
    "#     num_batches = 0\n",
    "#     num_classes = 80\n",
    "#     with torch.no_grad():  # 不计算梯度\n",
    "#         for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "#             images = images.to(device)\n",
    "\n",
    "#             # 模型前向传播\n",
    "#             output1, output2, output3 = model(images)\n",
    "\n",
    "#             batch_loss = 0\n",
    "#             for i in range(len(labels)):\n",
    "#                 label = labels[i].to(device)\n",
    "#                 num_objects = label.size(0)\n",
    "#                 num_anchors = 3\n",
    "#                 num_classes = loss_fn.num_classes\n",
    "\n",
    "#                 # 调整标签形状以匹配损失函数的期望输入\n",
    "#                 target1 = torch.zeros((1, num_anchors, num_classes + 5, 80, 80)).to(device)\n",
    "#                 target1[..., 5:(5 + num_classes), :num_objects, :num_objects] = torch.ones((num_classes, num_objects, num_objects))\n",
    "\n",
    "#                 target2 = torch.zeros((1, num_anchors, num_classes + 5, 40, 40)).to(device)\n",
    "#                 target2[..., 5:(5 + num_classes), :num_objects, :num_objects] = torch.ones((num_classes, num_objects, num_objects))\n",
    "\n",
    "#                 target3 = torch.zeros((1, num_anchors, num_classes + 5, 20, 20)).to(device)\n",
    "#                 target3[..., 5:(5 + num_classes), :num_objects, :num_objects] = torch.ones((num_classes, num_objects, num_objects))\n",
    "\n",
    "#                 # 计算损失\n",
    "#                 loss = loss_fn(output1[i].unsqueeze(0), output2[i].unsqueeze(0), output3[i].unsqueeze(0),\n",
    "#                              target1, target2, target3)\n",
    "#                 batch_loss += loss\n",
    "\n",
    "#             total_loss += batch_loss.item()\n",
    "#             num_batches += 1\n",
    "\n",
    "#             if (batch_idx + 1) % 10 == 0:\n",
    "#                 avg_loss = total_loss / num_batches\n",
    "#                 print(f\"Test Batch {batch_idx + 1}: Average Loss = {avg_loss}\")\n",
    "#                 total_loss = 0.0\n",
    "#                 num_batches = 0\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     num_classes = 80\n",
    "#     # 初始化模型\n",
    "#     model = YOLOv5(3, 64, 6, 2, 2)\n",
    "#     model.to(device)\n",
    "#     # 定义损失函数\n",
    "#     loss_fn = YOLOv5Loss(num_classes=80)\n",
    "\n",
    "#     # 加载保存的模型\n",
    "#     model.load_state_dict(torch.load('yolov5_model.pt', map_location=device))\n",
    "#     model.eval()\n",
    "\n",
    "#     # 定义优化器\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "#     # 调用测试函数\n",
    "#     test(model, test_dataloader, loss_fn, device)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355a971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolomaster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}